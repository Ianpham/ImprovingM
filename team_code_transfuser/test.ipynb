{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an image\n",
    "image = Image.open(\"/home/phamtam/Pictures/images.jpeg\")\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Apply the transformations to the image\n",
    "image_tensor = transform(image)\n",
    "\n",
    "# Add a batch dimension to the image tensor\n",
    "image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "# Create a grid of coordinates\n",
    "theta = torch.tensor([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0]\n",
    "], dtype=torch.float)\n",
    "theta = theta.unsqueeze(0)\n",
    "grid = F.affine_grid(theta, image_tensor.size())\n",
    "\n",
    "# Apply grid sampling to the image\n",
    "output = F.grid_sample(image_tensor, grid, align_corners=True)\n",
    "\n",
    "# Convert the output tensor to a PIL image\n",
    "output_image = transforms.ToPILImage()(output.squeeze(0))\n",
    "\n",
    "# Display the original and transformed images\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(image)\n",
    "axs[0].set_title(\"Original Image\")\n",
    "axs[0].axis(\"off\")\n",
    "axs[1].imshow(output_image)\n",
    "axs[1].set_title(\"Transformed Image\")\n",
    "axs[1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from functools import partial\n",
    "from typing import Optional, Callable, Any\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "from einops import rearrange, repeat\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "from fvcore.nn import FlopCountAnalysis, flop_count_str, flop_count, parameter_count\n",
    "DropPath.__repr__ = lambda self: f\"timm.DropPath({self.drop_prob})\"\n",
    "\n",
    "# import selective scan, \n",
    "try:\n",
    "    import selective_scan_cuda_oflex\n",
    "except Exception as e:\n",
    "    ...\n",
    "try:\n",
    "    import selective_scan_cuda_core\n",
    "except Exception as e:\n",
    "    ...\n",
    "\n",
    "try:\n",
    "    import selective_scan_cuda\n",
    "except Exception as e:\n",
    "    ...\n",
    "\n",
    "# fvcore flops\n",
    "\n",
    "def gather_by_angle(tensor, angle):\n",
    "    B, C, H, W = tensor.size()\n",
    "    rad_angle = math.radians(angle)\n",
    "\n",
    "    # step sizes in x and y\n",
    "    step_x = math.cos(rad_angle)\n",
    "    step_y = math.sin(rad_angle)\n",
    "    # create grid of indice\n",
    "    indices_x = torch.arange(0,W, device = tensor.device)\n",
    "    indices_y = torch.arange(0,H, device = tensor.device)\n",
    "    grid_x, grid_y = torch.meshgrid(indices_x, indices_y, indexing = 'xy')\n",
    "    \n",
    "    # starting position\n",
    "    start_x = (grid_y * step_x).round().long()\n",
    "    start_y = (grid_y * step_y).round().long()\n",
    "\n",
    "    # create the gathering indices\n",
    "    gather_indices = (start_x.unsqueeze(-1) + indices_x).clamp(0,W-1)\n",
    "    gather_indices = gather_indices.unsqueeze(0).unsqueeze(0).expand(B, C, -1, -1)\n",
    "\n",
    "    # gatehr the elements along the specified angle\n",
    "    gathered = tensor.gather(3, gather_indices)\n",
    "\n",
    "    return gathered.transpose(-1,-2).reshape(B,C,H*W)\n",
    "\n",
    "def scatter_by_angle(tensor_flat, original_shape, angle):\n",
    "    B, C, H, W = original_shape\n",
    "    rad_angle = math.radians(angle)\n",
    "    \n",
    "    # Compute the step sizes in the x and y directions based on the angle\n",
    "    step_x = math.cos(rad_angle)\n",
    "    step_y = math.sin(rad_angle)\n",
    "    \n",
    "    # Create a grid of indices for scattering\n",
    "    indices_x = torch.arange(0, W, device=tensor_flat.device)\n",
    "    indices_y = torch.arange(0, H, device=tensor_flat.device)\n",
    "    grid_x, grid_y = torch.meshgrid(indices_x, indices_y, indexing='xy')\n",
    "    \n",
    "    # Compute the starting positions for each row\n",
    "    start_x = (grid_y * step_x).round().long()\n",
    "    start_y = (grid_y * step_y).round().long()\n",
    "    \n",
    "    # Create the scattering indices\n",
    "    scatter_indices = (start_x.unsqueeze(-1) + indices_x).clamp(0, W-1)\n",
    "    scatter_indices = scatter_indices.unsqueeze(0).unsqueeze(0).expand(B, C, -1, -1)\n",
    "    \n",
    "    # Create an empty tensor to store the scattered result\n",
    "    result_tensor = torch.zeros(B, C, H, W, device=tensor_flat.device, dtype=tensor_flat.dtype)\n",
    "    \n",
    "    # Scatter the flattened tensor back to the original shape\n",
    "    result_tensor.scatter_(3, scatter_indices, tensor_flat.reshape(B, C, H, W))\n",
    "    \n",
    "    return result_tensor\n",
    "\n",
    "class SelectiveDirection(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        n_groups,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_groups = n_groups\n",
    "        self.n_group_channels = self.in_channels // self.n_groups\n",
    "        self.conv_offset = nn.Sequential(\n",
    "            nn.Conv2d(self.n_group_channels, self.n_group_channels, 3, 1, 1, groups=self.n_group_channels),\n",
    "            nn.LayerNorm(self.n_group_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.n_group_channels, 2, 1, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_groups = x.reshape(B, self.n_groups, self.n_group_channels, H, W)\n",
    "\n",
    "        # Divide the image into 9 sub-sections\n",
    "        sub_h, sub_w = H // 3, W // 3\n",
    "        sub_sections = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i == 1 and j == 1:\n",
    "                    continue  # Skip the center sub-section\n",
    "                sub_section = x_groups[..., i*sub_h:(i+1)*sub_h, j*sub_w:(j+1)*sub_w]\n",
    "                sub_sections.append(sub_section)\n",
    "\n",
    "        # Compute attention points for each sub-section\n",
    "        points = []\n",
    "        for sub_section in sub_sections:\n",
    "            sub_section_flat = sub_section.reshape(B * self.n_groups, self.n_group_channels, sub_h, sub_w)\n",
    "            sub_section_points = self.conv_offset(sub_section_flat)\n",
    "            sub_section_points = sub_section_points.reshape(B, self.n_groups, 2, 1, 1)\n",
    "            sub_section_points = sub_section_points.mean(dim=1, keepdim=True)\n",
    "            points.append(sub_section_points)\n",
    "\n",
    "        points = torch.cat(points, dim=1)\n",
    "        points = points.reshape(B, 8, 2, 1, 1)\n",
    "\n",
    "        # Compute angles from the center point to the learned points\n",
    "        angles = self.create_angle(points)\n",
    "\n",
    "        return points, angles\n",
    "\n",
    "    def create_angle(self, points):\n",
    "        B, _, _, _, _ = points.shape\n",
    "        center_x, center_y = 0.5, 0.5  # Assuming normalized coordinates\n",
    "\n",
    "        angles = []\n",
    "        for i in range(B):\n",
    "            batch_points = points[i].squeeze()  # Shape: (8, 2)\n",
    "            batch_angles = []\n",
    "            for j in range(8):\n",
    "                point_x, point_y = batch_points[j]\n",
    "                angle = math.atan2(point_y - center_y, point_x - center_x)\n",
    "                batch_angles.append(angle)\n",
    "            angles.append(batch_angles)\n",
    "\n",
    "        angles = torch.tensor(angles, device=points.device)\n",
    "        angles = angles.reshape(B, 8, 1, 1, 1)\n",
    "\n",
    "        return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "in_channels = 512\n",
    "n_groups = 32\n",
    "model = SelectiveDirection(in_channels, n_groups)\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = \"/home/phamtam/Pictures/images.jpeg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "print(input_tensor.shape)\n",
    "print(np.array(image).shape)\n",
    "# Forward pass through the SelectiveDirection module\n",
    "with torch.no_grad():\n",
    "    points, angles = model(input_tensor)\n",
    "\n",
    "# Visualize the learned attention points and angles on the input image\n",
    "def visualize_points_and_angles(image, points, angles):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "    center_x, center_y = image_width // 2, image_height // 2\n",
    "\n",
    "    for i in range(points.shape[1]):\n",
    "        point_x = int(points[0, i, 0, 0, 0].item() * image_width)\n",
    "        point_y = int(points[0, i, 1, 0, 0].item() * image_height)\n",
    "        angle = angles[0, i, 0, 0, 0].item()\n",
    "\n",
    "        # Draw the attention point\n",
    "        draw.ellipse((point_x - 2, point_y - 2, point_x + 2, point_y + 2), fill=\"red\")\n",
    "\n",
    "        # Draw the angle line\n",
    "        angle_x = center_x + 50 * math.cos(angle)\n",
    "        angle_y = center_y + 50 * math.sin(angle)\n",
    "        draw.line((center_x, center_y, angle_x, angle_y), fill=\"blue\", width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Visualize the points and angles on the input image\n",
    "visualized_image = visualize_points_and_angles(image, points, angles)\n",
    "visualized_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "from einops import rearrange\n",
    "\n",
    "class LayerNormProxy(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = rearrange(x,'b c h m  -> b h m c')\n",
    "        x = self.norm(x)\n",
    "        x = rearrange(x,'b h m c -> b c h m')\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define the SelectiveDirection module\n",
    "class SelectiveDirection(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        n_groups,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_groups = n_groups\n",
    "        self.n_group_channels = self.in_channels // self.n_groups\n",
    "        self.conv_offset = nn.Sequential(\n",
    "            nn.Conv2d(self.n_group_channels, self.n_group_channels, 3, 1, 1, groups=self.n_group_channels),\n",
    "            LayerNormProxy(self.n_group_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.n_group_channels, 2, 1, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x_groups = x.reshape(B, self.n_groups, self.n_group_channels, H, W)\n",
    "\n",
    "        # Divide the image into 9 sub-sections\n",
    "        sub_h, sub_w = H // 3, W // 3\n",
    "        sub_sections = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i == 1 and j == 1:\n",
    "                    continue  # Skip the center sub-section\n",
    "                sub_section = x_groups[..., i*sub_h:(i+1)*sub_h, j*sub_w:(j+1)*sub_w]\n",
    "                sub_sections.append(sub_section)\n",
    "\n",
    "        # Compute attention points for each sub-section\n",
    "        points = []\n",
    "        for sub_section in sub_sections:\n",
    "            sub_section_flat = sub_section.reshape(B * self.n_groups, self.n_group_channels, sub_h, sub_w)\n",
    "            sub_section_points = self.conv_offset(sub_section_flat)\n",
    "            sub_section_points = sub_section_points.reshape(B, self.n_groups, 2, 1, 1)\n",
    "            sub_section_points = sub_section_points.mean(dim=1, keepdim=True)\n",
    "            points.append(sub_section_points)\n",
    "\n",
    "        points = torch.cat(points, dim=1)\n",
    "        points = points.reshape(B, 8, 2, 1, 1)\n",
    "\n",
    "        # Compute angles from the center point to the learned points\n",
    "        angles = self.create_angle(points)\n",
    "\n",
    "        return points, angles\n",
    "\n",
    "    def create_angle(self, points):\n",
    "        B, _, _, _, _ = points.shape\n",
    "        center_x, center_y = 0.5, 0.5  # Assuming normalized coordinates\n",
    "\n",
    "        angles = []\n",
    "        for i in range(B):\n",
    "            batch_points = points[i].squeeze()  # Shape: (8, 2)\n",
    "            batch_angles = []\n",
    "            for j in range(8):\n",
    "                point_x, point_y = batch_points[j]\n",
    "                angle = math.atan2(point_y - center_y, point_x - center_x)\n",
    "                batch_angles.append(angle)\n",
    "            angles.append(batch_angles)\n",
    "\n",
    "        angles = torch.tensor(angles, device=points.device)\n",
    "        angles = angles.reshape(B, 8, 1, 1, 1)\n",
    "\n",
    "        return angles\n",
    "# Create an instance of the SelectiveDirection module\n",
    "in_channels = 3\n",
    "n_groups = 1\n",
    "model = SelectiveDirection(in_channels, n_groups)\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = \"/home/phamtam/Pictures/images.jpeg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Forward pass through the SelectiveDirection module\n",
    "with torch.no_grad():\n",
    "    points, angles = model(input_tensor)\n",
    "\n",
    "def visualize_points_and_angles(image, points, angles):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "    center_x, center_y = image_width // 2, image_height // 2\n",
    "\n",
    "    for i in range(points.shape[1]):\n",
    "        point_x = int(points[0, i, 0, 0, 0].item() * image_width)\n",
    "        point_y = int(points[0, i, 1, 0, 0].item() * image_height)\n",
    "        angle = angles[0, i, 0, 0, 0].item()\n",
    "\n",
    "        # Draw the attention point\n",
    "        draw.ellipse((point_x - 2, point_y - 2, point_x + 2, point_y + 2), fill=\"red\")\n",
    "\n",
    "        # Draw the angle line\n",
    "        angle_x = center_x + 50 * math.cos(angle)\n",
    "        angle_y = center_y + 50 * math.sin(angle)\n",
    "        draw.line((center_x, center_y, angle_x, angle_y), fill=\"blue\", width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Visualize the points and angles on the input image\n",
    "visualized_image = visualize_points_and_angles(image, points, angles)\n",
    "visualized_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw\n",
    "import math\n",
    "\n",
    "# Define the SelectiveDirection module\n",
    "class SelectiveDirection(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        n_groups,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.n_groups = n_groups\n",
    "        self.n_group_channels = self.in_channels // self.n_groups\n",
    "        self.conv_offset = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.in_channels, 3, 1, 1, groups=self.n_groups),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(self.in_channels, 2, 1, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Divide the image into 9 sub-sections\n",
    "        sub_h, sub_w = H // 3, W // 3\n",
    "        sub_sections = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i == 1 and j == 1:\n",
    "                    continue  # Skip the center sub-section\n",
    "                sub_section = x[:, :, i*sub_h:(i+1)*sub_h, j*sub_w:(j+1)*sub_w]\n",
    "                sub_sections.append(sub_section)\n",
    "\n",
    "        # Compute attention points for each sub-section\n",
    "        points = []\n",
    "        for sub_section in sub_sections:\n",
    "            sub_section_points = self.conv_offset(sub_section)\n",
    "            sub_section_points = sub_section_points.mean(dim=(2, 3)).unsqueeze(-1).unsqueeze(-1)\n",
    "            points.append(sub_section_points)\n",
    "\n",
    "        points = torch.cat(points, dim=1)\n",
    "        points = points.reshape(B, 8, 2, 1, 1)\n",
    "        print(points.shape)\n",
    "        # Compute angles from the center point to the learned points\n",
    "        angles = self.create_angle(points)\n",
    "\n",
    "        return points, angles\n",
    "\n",
    "    def create_angle(self, points):\n",
    "        B, _, _, _, _ = points.shape\n",
    "        center_x, center_y = 0.5, 0.5  # Assuming normalized coordinates\n",
    "\n",
    "        angles = []\n",
    "        for i in range(B):\n",
    "            batch_points = points[i].squeeze()  # Shape: (8, 2)\n",
    "            batch_angles = []\n",
    "            for j in range(8):\n",
    "                point_x, point_y = batch_points[j]\n",
    "                angle = math.atan2(point_y - center_y, point_x - center_x)\n",
    "                batch_angles.append(angle)\n",
    "            angles.append(batch_angles)\n",
    "\n",
    "        angles = torch.tensor(angles, device=points.device)\n",
    "        angles = angles.reshape(B, 8, 1, 1, 1)\n",
    "\n",
    "        return angles\n",
    "\n",
    "# Create an instance of the SelectiveDirection module\n",
    "in_channels = 3\n",
    "n_groups = 1\n",
    "model = SelectiveDirection(in_channels, n_groups)\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = \"/home/phamtam/Pictures/images.jpeg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Forward pass through the SelectiveDirection module\n",
    "with torch.no_grad():\n",
    "    points, angles = model(input_tensor)\n",
    "\n",
    "def visualize_points_and_angles(image, points, angles):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    image_width, image_height = image.size\n",
    "    center_x, center_y = image_width // 2, image_height // 2\n",
    "\n",
    "    for i in range(points.shape[1]):\n",
    "        point_x = int(points[0, i, 0, 0, 0].item() * image_width)\n",
    "        point_y = int(points[0, i, 1, 0, 0].item() * image_height)\n",
    "        angle = angles[0, i, 0, 0, 0].item()\n",
    "\n",
    "        # Draw the attention point\n",
    "        draw.ellipse((point_x - 2, point_y - 2, point_x + 2, point_y + 2), fill=\"red\")\n",
    "\n",
    "        # Draw the angle line\n",
    "        angle_x = center_x + 50 * math.cos(angle)\n",
    "        angle_y = center_y + 50 * math.sin(angle)\n",
    "        draw.line((center_x, center_y, angle_x, angle_y), fill=\"blue\", width=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Visualize the points and angles on the input image\n",
    "visualized_image = visualize_points_and_angles(image, points, angles)\n",
    "visualized_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
